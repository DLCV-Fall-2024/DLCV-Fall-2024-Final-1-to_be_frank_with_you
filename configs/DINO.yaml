project_name: null
run_name: null
seed: 42
lora_rank: -1
model:
  model_id: llava-hf/llava-1.5-7b-hf
  device: cuda
  patch_size: 14
  vision_feature_select_strategy: full
  gradient_checkpointing: false
  lora_config:
    r: 16
    lora_alpha: 32
    target_modules:
    - q_proj
    - v_proj
    - multi_modal_projector.linear_1
    - multi_modal_projector.linear_2
    exclude_modules: vision_tower.*
    lora_dropout: 0.1
    use_dora: true
    bias: none
    task_type: CAUSAL_LM
pipeline:
  debug: false
dataset:
  dataset_path: data
  seed: 42
  num_workers: 10
  prefetch_factor: 2
optimization:
  epochs: 100
  lr: 3.0e-05
  batch_size: 1
  optimizer_type: default
  accumulation_steps: 4
